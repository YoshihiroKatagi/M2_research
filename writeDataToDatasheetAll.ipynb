{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd0b6fa4-e3c4-4fe4-a5bf-0c1bf8c36c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated_date: 2022/12/07 18:24\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "##### 使用するライブラリ・モジュールのインポート\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import cv2\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "# 実行時間取得\n",
    "updated_date = datetime.datetime.now().strftime('%Y/%m/%d %H:%M')\n",
    "print(\"updated_date: \" + updated_date)\n",
    "print(type(updated_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f24317-0d0d-4b86-bcff-f63fd2dd81fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################  データフォルダ・データシート作成  ###################\n",
      "current_directory: C:/Users/katagi/Desktop/Research/UltrasoundImaging\n",
      "data_path: C:/Users/katagi/Desktop/Research/UltrasoundImaging/Data\n",
      "datasheet_all_path: C:/Users/katagi/Desktop/Research/UltrasoundImaging/Data/datasheet_all.csv\n",
      "Data folder already exists.\n",
      "Datasheet already exists.\n",
      "#####################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### データフォルダ・データシート作成（データフォルダが存在しない場合のみ実行）\n",
    "print(\"###################  データフォルダ・データシート作成  ###################\")\n",
    "\n",
    "current_directory = os.getcwd().replace(os.sep, \"/\")\n",
    "print(\"current_directory: \" + current_directory)\n",
    "\n",
    "data_path = current_directory + \"/Data\"\n",
    "print(\"data_path: \" + data_path)\n",
    "\n",
    "datasheet_all_path = data_path + \"/datasheet_all\" + \".csv\"\n",
    "print(\"datasheet_all_path: \" + datasheet_all_path)\n",
    "\n",
    "cols_for_all = [\"Data No\", \"Gonio\", \"Echo\", \"Date\", \"Subject\", \"Pattern\", \"Trial Num\", \"Depth\", \"RMSE\", \"R2\", \"Corrcoef\", \"Updated Date\"]\n",
    "\n",
    "# データフォルダが存在しなければ作成\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    print(\"Data folder was successfully created.\")\n",
    "else:\n",
    "    print(\"Data folder already exists.\")\n",
    "\n",
    "# datasheet_allが存在しなければ作成\n",
    "if not os.path.exists(datasheet_all_path):\n",
    "    df_for_all = pd.DataFrame(columns=cols_for_all)\n",
    "    df_for_all.set_index(\"Data No\", inplace=True)\n",
    "    # datasheet_allへの新規書き込み\n",
    "    df_for_all.to_csv(datasheet_all_path, encoding=\"shift_jis\")\n",
    "    print(\"datasheet_all was successfully created.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Datasheet already exists.\")\n",
    "print(\"#####################################################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "717d36e3-e1db-481f-a045-571eb3cf5d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################  datasheet_all.csv 読み込み  ###################\n",
      "-------------  datasheet_all_df  ---------------------\n",
      "                    Gonio                 Echo        Date Subject  Pattern  \\\n",
      "Data No                                                                       \n",
      "1        202210211613.csv  20221021 161310.mp4  20221021.0  Katagi      3.0   \n",
      "2        202210211616.csv  20221021 161620.mp4  20221021.0  Katagi      3.0   \n",
      "3        202210211619.csv  20221021 161915.mp4  20221021.0  Katagi      3.0   \n",
      "4        202210211622.csv  20221021 162244.mp4  20221021.0  Katagi      3.0   \n",
      "5        202210211626.csv  20221021 162613.mp4  20221021.0  Katagi      3.0   \n",
      "6        202211081334.csv  20221108 133448.mp4  20221108.0  Katagi      1.0   \n",
      "7        202211081339.csv  20221108 133918.mp4  20221108.0  Katagi      1.0   \n",
      "8        202211081343.csv  20221108 134301.mp4  20221108.0  Katagi      1.0   \n",
      "9        202211081345.csv  20221108 134549.mp4  20221108.0  Katagi      1.0   \n",
      "10       202211081348.csv  20221108 134845.mp4  20221108.0  Katagi      1.0   \n",
      "11       202211081352.csv  20221108 135205.mp4  20221108.0  Katagi      1.0   \n",
      "12       202211081355.csv  20221108 135505.mp4  20221108.0  Katagi      1.0   \n",
      "13       202211081357.csv  20221108 135748.mp4  20221108.0  Katagi      1.0   \n",
      "14       202211081401.csv  20221108 140103.mp4  20221108.0  Katagi      1.0   \n",
      "15       202211081404.csv  20221108 140434.mp4  20221108.0  Katagi      1.0   \n",
      "16       202212061614.csv  20221206 161438.mp4  20221204.0  Katagi      1.0   \n",
      "17       202212061617.csv  20221206 161753.mp4  20221204.0  Katagi      1.0   \n",
      "18       202212061621.csv  20221206 162112.mp4  20221204.0  Katagi      1.0   \n",
      "19       202212061624.csv  20221206 162430.mp4  20221204.0  Katagi      1.0   \n",
      "20       202212061627.csv  20221206 162753.mp4  20221204.0  Katagi      1.0   \n",
      "21       202212061639.csv  20221206 163918.mp4  20221205.0  Katagi      1.0   \n",
      "22       202212061642.csv  20221206 164249.mp4  20221205.0  Katagi      1.0   \n",
      "23       202212061646.csv  20221206 164656.mp4  20221205.0  Katagi      1.0   \n",
      "24       202212061650.csv  20221206 165033.mp4  20221205.0  Katagi      1.0   \n",
      "25       202212061653.csv  20221206 165355.mp4  20221205.0  Katagi      1.0   \n",
      "26       202212061527.csv  20221206 152719.mp4  20221206.0  Katagi      1.0   \n",
      "27       202212061531.csv  20221206 153108.mp4  20221206.0  Katagi      1.0   \n",
      "28       202212061534.csv  20221206 153436.mp4  20221206.0  Katagi      1.0   \n",
      "29       202212061538.csv  20221206 153804.mp4  20221206.0  Katagi      1.0   \n",
      "30       202212061541.csv  20221206 154136.mp4  20221206.0  Katagi      1.0   \n",
      "31       202212061546.csv  20221206 154601.mp4  20221206.0  Katagi      2.0   \n",
      "32       202212061548.csv  20221206 154847.mp4  20221206.0  Katagi      2.0   \n",
      "33       202212061551.csv  20221206 155127.mp4  20221206.0  Katagi      2.0   \n",
      "34       202212061554.csv  20221206 155411.mp4  20221206.0  Katagi      2.0   \n",
      "35       202212061556.csv  20221206 155658.mp4  20221206.0  Katagi      2.0   \n",
      "\n",
      "         Trial Num  Depth       RMSE        R2  Corrcoef      Updated Date  \n",
      "Data No                                                                     \n",
      "1              1.0   20.0  16.089504  0.239279  0.490837  2022/11/30 19:11  \n",
      "2              2.0   20.0  11.857474  0.272827  0.525024  2022/12/05 18:52  \n",
      "3              3.0   20.0  13.898147  0.358044  0.658014  2022/12/05 19:10  \n",
      "4              4.0   20.0   7.428312  0.696605  0.834771  2022/12/05 19:21  \n",
      "5              5.0   20.0  14.579082  0.102034  0.509973  2022/12/05 19:30  \n",
      "6              1.0   30.0  16.472820  0.448128  0.719522  2022/12/06 09:58  \n",
      "7              2.0   30.0  16.233118  0.457288  0.688575  2022/12/06 09:58  \n",
      "8              3.0   30.0  14.485802  0.338089  0.602070  2022/12/06 09:58  \n",
      "9              4.0   30.0  13.010647  0.608193  0.807010  2022/12/06 09:58  \n",
      "10             5.0   30.0  15.504394  0.434689  0.662242  2022/12/06 09:58  \n",
      "11             6.0   30.0   7.358158  0.834976  0.927250  2022/12/06 15:11  \n",
      "12             7.0   30.0   7.349553  0.830884  0.919354  2022/12/06 15:11  \n",
      "13             8.0   30.0   9.817593  0.713534  0.912486  2022/12/06 15:11  \n",
      "14             9.0   30.0   9.015793  0.745447  0.889065  2022/12/06 15:11  \n",
      "15            10.0   30.0   9.458311  0.725027  0.862560  2022/12/06 15:11  \n",
      "16             1.0   30.0        NaN       NaN       NaN  2022/12/07 18:22  \n",
      "17             2.0   30.0        NaN       NaN       NaN  2022/12/07 18:22  \n",
      "18             3.0   30.0        NaN       NaN       NaN  2022/12/07 18:22  \n",
      "19             4.0   30.0        NaN       NaN       NaN  2022/12/07 18:22  \n",
      "20             5.0   30.0        NaN       NaN       NaN  2022/12/07 18:22  \n",
      "21             1.0   30.0        NaN       NaN       NaN  2022/12/07 18:22  \n",
      "22             2.0   30.0        NaN       NaN       NaN  2022/12/07 18:22  \n",
      "23             3.0   30.0        NaN       NaN       NaN  2022/12/07 18:22  \n",
      "24             4.0   30.0        NaN       NaN       NaN  2022/12/07 18:22  \n",
      "25             5.0   30.0        NaN       NaN       NaN  2022/12/07 18:22  \n",
      "26             1.0   30.0        NaN       NaN       NaN  2022/12/07 18:23  \n",
      "27             2.0   30.0        NaN       NaN       NaN  2022/12/07 18:23  \n",
      "28             3.0   30.0        NaN       NaN       NaN  2022/12/07 18:23  \n",
      "29             4.0   30.0        NaN       NaN       NaN  2022/12/07 18:23  \n",
      "30             5.0   30.0        NaN       NaN       NaN  2022/12/07 18:23  \n",
      "31             1.0   30.0        NaN       NaN       NaN  2022/12/07 18:23  \n",
      "32             2.0   30.0        NaN       NaN       NaN  2022/12/07 18:23  \n",
      "33             3.0   30.0        NaN       NaN       NaN  2022/12/07 18:23  \n",
      "34             4.0   30.0        NaN       NaN       NaN  2022/12/07 18:23  \n",
      "35             5.0   30.0        NaN       NaN       NaN  2022/12/07 18:23  \n",
      "------------------------------------------------------\n",
      "data_No_list: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "data_last_No: 35\n",
      "#####################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### datasheet_all.csv 読み込み\n",
    "print(\"###################  datasheet_all.csv 読み込み  ###################\")\n",
    "\n",
    "# インデックスを\"Data No\"としたデータフレームとして読み込み\n",
    "datasheet_all_df = pd.read_csv(datasheet_all_path, header=0, index_col=[\"Data No\"], encoding='shift_jis')\n",
    "datasheet_all_df = datasheet_all_df.dropna(how='all', axis=0)\n",
    "print(\"-------------  datasheet_all_df  ---------------------\")\n",
    "print(datasheet_all_df)\n",
    "print(\"------------------------------------------------------\")\n",
    "\n",
    "data_No_list = datasheet_all_df.index.tolist()\n",
    "if datasheet_all_df.empty:\n",
    "    data_last_No = 0\n",
    "else:\n",
    "    data_last_No = data_No_list[-1]\n",
    "print(\"data_No_list: \" + str(data_No_list))\n",
    "print(\"data_last_No: \" + str(data_last_No))\n",
    "print(\"#####################################################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18cc1c10-d718-4b67-a1c6-897c4bfb0a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################  DATA_INFO(date, subject, pattern) を入力  ###################\n",
      "DATA_INFOを入力してdatasheet_all.csvに書き込むデータを指定してください．\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Date:  20221206\n",
      "Subject:  Katagi\n",
      "Pattern:  3\n",
      "Depth:  30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_INFO: 20221206_Katagi_pattern3\n",
      "#####################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### DATA_INFO(date, subject, pattern) を入力\n",
    "print(\"###################  DATA_INFO(date, subject, pattern) を入力  ###################\")\n",
    "print(\"DATA_INFOを入力してdatasheet_all.csvに書き込むデータを指定してください．\")\n",
    "\n",
    "## DATA_INFO\n",
    "# 実験日\n",
    "date = input(\"Date: \")\n",
    "\n",
    "# 被験者\n",
    "subject = input(\"Subject: \")\n",
    "\n",
    "# 実験パターン\n",
    "pattern = input(\"Pattern: \")\n",
    "\n",
    "# 深度\n",
    "depth = input(\"Depth: \")\n",
    "\n",
    "\n",
    "info_str = date + \"_\" + subject + \"_pattern\" + pattern\n",
    "data_per_info_path = data_path + \"/\" + info_str\n",
    "print(\"DATA_INFO: \" + info_str)\n",
    "\n",
    "# data_per_info フォルダが存在しなければ任意で作成\n",
    "if not os.path.exists(data_per_info_path):\n",
    "    make_new = input(\"該当するフォルダがありません．新規作成しますか？(yes/no)\")\n",
    "    if make_new == \"yes\":\n",
    "        os.makedirs(data_per_info_path)\n",
    "        print(\"\\nフォルダを新規作成しました．\\n\\n\")\n",
    "        print(\"このフォルダに実験データを入れてからもう一度実行してください．\")\n",
    "        print(\"※それぞれのフォルダ名は'GonioData'，'EchoData'とすること．\")\n",
    "        raise Exception(\"Data doesn't exist.\")\n",
    "    else:\n",
    "        raise Exception(\"Try again.\")\n",
    "print(\"#####################################################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c043aed-51bd-459a-8337-4e5f1e846dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################  データがなければエラーを表示  ###################\n",
      "#####################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### データがなければエラーを表示\n",
    "print(\"###################  データがなければエラーを表示  ###################\")\n",
    "\n",
    "gonio_data_path = data_per_info_path + \"/GonioData\"\n",
    "echo_data_path = data_per_info_path + \"/EchoData\"\n",
    "if not os.path.exists(gonio_data_path):\n",
    "    print(\"ゴニオデータがありません\")\n",
    "    raise Exception(\"GonioData doesn't exist.\")\n",
    "if not os.path.exists(echo_data_path):\n",
    "    print(\"エコーデータがありません\")\n",
    "    raise Exception(\"EchoData doesn't exist.\")\n",
    "print(\"#####################################################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fd2851-e898-4d2f-b18a-999a4d80d146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################  ゴニオ，エコーデータがあればリストで取得  ###################\n",
      "gonio_files: ['202212061559.csv', '202212061602.csv', '202212061605.csv', '202212061607.csv', '202212061610.csv']\n",
      "echo_files: ['20221206 155955.mp4', '20221206 160233.mp4', '20221206 160509.mp4', '20221206 160751.mp4', '20221206 161040.mp4']\n",
      "#####################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ゴニオ，エコーデータがあればリストで取得\n",
    "print(\"###################  ゴニオ，エコーデータがあればリストで取得  ###################\")\n",
    "# ゴニオデータファイルをリストで取得\n",
    "gonio_files = list()\n",
    "for file in os.listdir(gonio_data_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        gonio_files.append(file)\n",
    "\n",
    "# エコーデータファイルをリストで取得\n",
    "echo_files = list()\n",
    "for file in os.listdir(echo_data_path):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        echo_files.append(file)\n",
    "\n",
    "print(\"gonio_files: \" + str(gonio_files))\n",
    "print(\"echo_files: \" + str(echo_files))\n",
    "print(\"#####################################################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0930fc3-1986-4383-a712-67c6c0112f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################  datasheet_all.csvへ書き込み  ###################\n",
      "num_of_trial: 5\n",
      "-------------  new_df_for_write  ---------------------\n",
      "                    Gonio                 Echo      Date Subject Pattern  \\\n",
      "Data No                                                                    \n",
      "36       202212061559.csv  20221206 155955.mp4  20221206  Katagi       3   \n",
      "37       202212061602.csv  20221206 160233.mp4  20221206  Katagi       3   \n",
      "38       202212061605.csv  20221206 160509.mp4  20221206  Katagi       3   \n",
      "39       202212061607.csv  20221206 160751.mp4  20221206  Katagi       3   \n",
      "40       202212061610.csv  20221206 161040.mp4  20221206  Katagi       3   \n",
      "\n",
      "        Trial Num Depth RMSE R2 Corrcoef      Updated Date  \n",
      "Data No                                                     \n",
      "36              1    30                   2022/12/07 18:24  \n",
      "37              2    30                   2022/12/07 18:24  \n",
      "38              3    30                   2022/12/07 18:24  \n",
      "39              4    30                   2022/12/07 18:24  \n",
      "40              5    30                   2022/12/07 18:24  \n",
      "------------------------------------------------------\n",
      "datasheet_all.csvに新しくデータを書き込みました．\n",
      "#####################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### datasheet_all.csvへ書き込み\n",
    "print(\"###################  datasheet_all.csvへ書き込み  ###################\")\n",
    "# 試行数\n",
    "num_of_trial = len(gonio_files)\n",
    "print(\"num_of_trial: \" + str(num_of_trial))\n",
    "\n",
    "# 書き込み用のデータフレームを用意\n",
    "new_df_for_write = pd.DataFrame(columns=cols_for_all)\n",
    "new_df_for_write.set_index(\"Data No\", inplace=True)\n",
    "\n",
    "# 各試行ごとのデータ取得\n",
    "for trial in range(num_of_trial):\n",
    "    # 試行番号\n",
    "    trial_num = trial + 1\n",
    "    \n",
    "    # データ番号\n",
    "    data_No = data_last_No + trial_num\n",
    "    \n",
    "    ## DATA_PATH\n",
    "    # ゴニオファイル名\n",
    "    gonio_file = gonio_files[trial]\n",
    "\n",
    "    # エコーファイル名\n",
    "    echo_file = echo_files[trial]\n",
    "    \n",
    "    # 各試行ごとのデータフレームを作成\n",
    "    new_data = [(data_No, gonio_file, echo_file, date, subject, pattern, trial_num, depth, \"\", \"\", \"\", updated_date)]\n",
    "    new_df_element = pd.DataFrame(data=new_data, columns=cols_for_all)\n",
    "    new_df_element.set_index(\"Data No\", inplace=True)\n",
    "    \n",
    "    # 書き込み用データフレームに追加\n",
    "    new_df_for_write = new_df_for_write.append(new_df_element)\n",
    "\n",
    "print(\"-------------  new_df_for_write  ---------------------\")\n",
    "print(new_df_for_write)\n",
    "print(\"------------------------------------------------------\")\n",
    "\n",
    "# datasheet_all.csvに書き込み\n",
    "datasheet_all_df = datasheet_all_df.append(new_df_for_write)\n",
    "datasheet_all_df.to_csv(datasheet_all_path, encoding=\"shift_jis\")\n",
    "\n",
    "print(\"datasheet_all.csvに新しくデータを書き込みました．\")\n",
    "print(\"#####################################################################\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenCV",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
